{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOzut3WandrEP+vNe/q3vgU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"jXPVYiWCAlmg","executionInfo":{"status":"ok","timestamp":1731865323449,"user_tz":-300,"elapsed":461,"user":{"displayName":"Magzhan Khorshat","userId":"05710964167967277441"}}},"outputs":[],"source":["# !pip install transformers datasets"]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from datasets import Dataset\n","from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n"],"metadata":{"id":"2ZI95PszAr7b","executionInfo":{"status":"ok","timestamp":1731865908399,"user_tz":-300,"elapsed":25927,"user":{"displayName":"Magzhan Khorshat","userId":"05710964167967277441"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv(\"dataset.csv\")\n","symptoms = data['symptoms']\n","diseases = data['disease']"],"metadata":{"id":"QIwOAEibAr5-","executionInfo":{"status":"ok","timestamp":1731865908399,"user_tz":-300,"elapsed":3,"user":{"displayName":"Magzhan Khorshat","userId":"05710964167967277441"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["label_encoder = LabelEncoder()\n","data['disease_encoded'] = label_encoder.fit_transform(diseases)\n","temp_texts, test_texts, temp_labels, test_labels = train_test_split(\n","    symptoms, data['disease_encoded'], test_size=0.2, random_state=42\n",")\n","train_texts, val_texts, train_labels, val_labels = train_test_split(\n","    temp_texts, temp_labels, test_size=0.25, random_state=42\n",")\n"],"metadata":{"id":"7Ct8-DNVAr4T","executionInfo":{"status":"ok","timestamp":1731865908399,"user_tz":-300,"elapsed":3,"user":{"displayName":"Magzhan Khorshat","userId":"05710964167967277441"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def train_and_evaluate(model_name, train_texts, val_texts, train_labels, val_labels):\n","\n","    if model_name == \"describeai/gemini\":\n","        tokenizer = AutoTokenizer.from_pretrained(\"describeai/gemini\")\n","        model = AutoModelForSequenceClassification.from_pretrained(\"describeai/gemini\", num_labels=len(label_encoder.classes_))\n","    else:\n","        tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","        tokenizer.pad_token = tokenizer.eos_token  # Set padding token\n","        model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=len(label_encoder.classes_))\n","        model.config.pad_token_id = tokenizer.eos_token_id\n","\n","    # Tokenize data\n","    train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n","    val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)\n","    train_dataset = Dataset.from_dict({\n","        'input_ids': train_encodings['input_ids'],\n","        'attention_mask': train_encodings['attention_mask'],\n","        'labels': list(train_labels)\n","    })\n","    val_dataset = Dataset.from_dict({\n","        'input_ids': val_encodings['input_ids'],\n","        'attention_mask': val_encodings['attention_mask'],\n","        'labels': list(val_labels)\n","    })\n","\n","    # Define training arguments\n","    training_args = TrainingArguments(\n","        output_dir=f'./results/{model_name}',\n","        num_train_epochs=5,\n","        per_device_train_batch_size=16,\n","        per_device_eval_batch_size=64,\n","        warmup_steps=100,\n","        weight_decay=0.01,\n","        logging_dir=f'./logs/{model_name}',\n","        eval_strategy=\"epoch\",\n","        save_strategy=\"epoch\",\n","        logging_steps=10,\n","        load_best_model_at_end=True,\n","        metric_for_best_model=\"eval_loss\",\n","        greater_is_better=False,\n","    )\n","\n","    # Initialize Trainer\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=val_dataset,\n","    )\n","\n","    # Train and evaluate the model\n","    trainer.train()\n","    eval_results = trainer.evaluate()\n","    print(f\"Evaluation Results for {model_name}:\", eval_results)\n","\n","    # Save the model and tokenizer\n","    model.save_pretrained(f'./{model_name}-disease-prediction')\n","    tokenizer.save_pretrained(f'./{model_name}-disease-prediction')\n","\n","    return model, tokenizer\n"],"metadata":{"id":"xgxvtez3Ar2l","executionInfo":{"status":"ok","timestamp":1731865908399,"user_tz":-300,"elapsed":2,"user":{"displayName":"Magzhan Khorshat","userId":"05710964167967277441"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, tokenizer, model_name):\n","    test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=128)\n","    test_dataset = Dataset.from_dict({\n","        'input_ids': test_encodings['input_ids'],\n","        'attention_mask': test_encodings['attention_mask'],\n","        'labels': list(test_labels),\n","    })\n","\n","    # Initialize Trainer for evaluation\n","    trainer = Trainer(\n","        model=model,\n","        args=TrainingArguments(\n","            output_dir=f'./results/{model_name}/eval',\n","            per_device_eval_batch_size=64\n","        )\n","    )\n","\n","    # Evaluate the model\n","    eval_results = trainer.evaluate(eval_dataset=test_dataset)\n","    print(f\"Evaluation Results for {model_name}:\", eval_results)\n","\n","    # Generate predictions\n","    raw_predictions = trainer.predict(test_dataset)\n","    predictions = np.argmax(raw_predictions.predictions, axis=1)\n","\n","    # Custom metrics\n","    accuracy = accuracy_score(test_labels, predictions)\n","    precision, recall, f1, _ = precision_recall_fscore_support(test_labels, predictions, average=\"weighted\")\n","    print(f\"Metrics for {model_name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n","\n","    # Classification report\n","    unique_labels = np.unique(np.concatenate((test_labels, predictions)))\n","    class_report = classification_report(test_labels, predictions, labels=unique_labels, target_names=label_encoder.classes_[unique_labels])\n","    print(f\"Classification Report for {model_name}:\\n\", class_report)"],"metadata":{"id":"8PFcvtedA6am","executionInfo":{"status":"ok","timestamp":1731865908399,"user_tz":-300,"elapsed":2,"user":{"displayName":"Magzhan Khorshat","userId":"05710964167967277441"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["gpt2_model, gpt2_tokenizer = train_and_evaluate(\"gpt2\", train_texts, val_texts, train_labels, val_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"id":"PVkWl8N3Ar03","executionInfo":{"status":"ok","timestamp":1731865632273,"user_tz":-300,"elapsed":269279,"user":{"displayName":"Magzhan Khorshat","userId":"05710964167967277441"}},"outputId":"0efd8399-51e7-4f4f-eaba-58bb51716690"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mghostmaga\u001b[0m (\u001b[33mghostmaga-nazarbayev-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.18.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20241117_174253-1j6b4y8v</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/ghostmaga-nazarbayev-university/huggingface/runs/1j6b4y8v' target=\"_blank\">./results/gpt2</a></strong> to <a href='https://wandb.ai/ghostmaga-nazarbayev-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/ghostmaga-nazarbayev-university/huggingface' target=\"_blank\">https://wandb.ai/ghostmaga-nazarbayev-university/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/ghostmaga-nazarbayev-university/huggingface/runs/1j6b4y8v' target=\"_blank\">https://wandb.ai/ghostmaga-nazarbayev-university/huggingface/runs/1j6b4y8v</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [20/20 03:55, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>7.345770</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>6.982092</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>7.281100</td>\n","      <td>6.583929</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>7.281100</td>\n","      <td>6.646929</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>5.909600</td>\n","      <td>7.013490</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 : < :]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluation Results for gpt2: {'eval_loss': 6.58392858505249, 'eval_runtime': 2.9188, 'eval_samples_per_second': 6.852, 'eval_steps_per_second': 0.343, 'epoch': 5.0}\n"]}]},{"cell_type":"code","source":["gemini_model, gemini_tokenizer = train_and_evaluate(\"describeai/gemini\", train_texts, val_texts, train_labels, val_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"6gySzvqHN3pb","outputId":"538b92c6-ea14-4f52-9fb5-4c0785c5d670"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at describeai/gemini and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mghostmaga\u001b[0m (\u001b[33mghostmaga-nazarbayev-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.18.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20241117_175200-x2pj7bpa</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/ghostmaga-nazarbayev-university/huggingface/runs/x2pj7bpa' target=\"_blank\">./results/describeai/gemini</a></strong> to <a href='https://wandb.ai/ghostmaga-nazarbayev-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/ghostmaga-nazarbayev-university/huggingface' target=\"_blank\">https://wandb.ai/ghostmaga-nazarbayev-university/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/ghostmaga-nazarbayev-university/huggingface/runs/x2pj7bpa' target=\"_blank\">https://wandb.ai/ghostmaga-nazarbayev-university/huggingface/runs/x2pj7bpa</a>"]},"metadata":{}}]},{"cell_type":"code","source":["evaluate_model(gpt2_model, gpt2_tokenizer, \"gpt2\")\n","evaluate_model(gemini_model, gemini_tokenizer, \"describeai/gemini\")"],"metadata":{"id":"LAU2y7fVArzI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"U646SIbvArxQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VC56NMq-Arvb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4gXKBf7kArtk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9wJHmNpJArr5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_il7rWavArqP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"J7yOYZEEAroQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"M6WseN0hArlw"},"execution_count":null,"outputs":[]}]}